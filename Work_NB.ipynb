{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc53171-b635-471d-a044-54129e9dd720",
   "metadata": {},
   "source": [
    "## Work Notebook\n",
    "### Algorithm of Hybrid Rec Engine - find similar products according a tag classifier followed by cosine similarity by Spacy embeddings of reviewText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e7da05d0-65dd-4620-ae13-eae74033ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f194a513-49b8-4b2a-acb6-320ab08637fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                          | 200/1689188 [12:23:59<104716:03:48, 223.20s/it]\n"
     ]
    }
   ],
   "source": [
    "#loading downloaded data\n",
    "df=pd.read_json('~/Downloads/reviews_Electronics_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb82bf-99dd-4bc3-9cce-e8473016be2f",
   "metadata": {},
   "source": [
    "### Loading pickled webscraping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d2ebff01-6505-462c-96a5-96384378d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('load_df.pickle', 'rb') as file:\n",
    "    load_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4228c-9fc2-4257-a25b-9886d827111c",
   "metadata": {},
   "source": [
    "### We will train a model that classifies user input (item) into appropriate tag labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9447638b-ffda-43e1-a491-eb9315eec14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>item</th>\n",
       "      <th>tag</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>[Rand McNally 528881469 7-inch Intelliroute TN...</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>$399.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>[Rand McNally 528881469 7-inch Intelliroute TN...</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>$399.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "      <td>[Rand McNally 528881469 7-inch Intelliroute TN...</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>$399.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>[Rand McNally 528881469 7-inch Intelliroute TN...</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>$399.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "      <td>[Rand McNally 528881469 7-inch Intelliroute TN...</td>\n",
       "      <td>Trucking GPS</td>\n",
       "      <td>$399.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin              reviewerName   helpful  \\\n",
       "0   AO94DHGC771SJ  0528881469                   amazdnu    [0, 0]   \n",
       "1   AMO214LNFCEI4  0528881469           Amazon Customer  [12, 15]   \n",
       "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman  [43, 45]   \n",
       "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   [9, 10]   \n",
       "4  A24EV6RXELQZ63  0528881469               Wayne Smith    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...        5   \n",
       "1  I'm a professional OTR truck driver, and I bou...        1   \n",
       "2  Well, what can I say.  I've had this unit in m...        3   \n",
       "3  Not going to write a long review, even thought...        2   \n",
       "4  I've had mine for a year and here's what we go...        1   \n",
       "\n",
       "                                  summary  unixReviewTime   reviewTime  \\\n",
       "0                         Gotta have GPS!      1370131200   06 2, 2013   \n",
       "1                       Very Disappointed      1290643200  11 25, 2010   \n",
       "2                          1st impression      1283990400   09 9, 2010   \n",
       "3                 Great grafics, POOR GPS      1290556800  11 24, 2010   \n",
       "4  Major issues, only excuses for support      1317254400  09 29, 2011   \n",
       "\n",
       "                                                item           tag    price  \n",
       "0  [Rand McNally 528881469 7-inch Intelliroute TN...  Trucking GPS  $399.99  \n",
       "1  [Rand McNally 528881469 7-inch Intelliroute TN...  Trucking GPS  $399.99  \n",
       "2  [Rand McNally 528881469 7-inch Intelliroute TN...  Trucking GPS  $399.99  \n",
       "3  [Rand McNally 528881469 7-inch Intelliroute TN...  Trucking GPS  $399.99  \n",
       "4  [Rand McNally 528881469 7-inch Intelliroute TN...  Trucking GPS  $399.99  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fa6479f3-1620-4696-9a43-b810733a74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod=load_df[['item','tag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f6906984-dfa3-45be-960e-6671a20322f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list=[]\n",
    "\n",
    "for i in range(702972):\n",
    "    try:\n",
    "        if len(df_mod.item[i][0]) >= 1:\n",
    "            item_list.append(df_mod.item[i][0])\n",
    "    except:\n",
    "        item_list.append(np.nan)\n",
    "        continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "33ba9e51-89d2-4003-a899-d3759ecf8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/48/3rfqt3q17zj4zsvn_9rh50br0000gn/T/ipykernel_10716/1714449863.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mod['item']=pd.Series(item_list)\n"
     ]
    }
   ],
   "source": [
    "df_mod['item']=pd.Series(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c44e91e8-f57b-4b7e-9f7e-9193652b4b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_mod.tag.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fcf86073-fb0e-4d31-a7f6-c1098f548040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyng/miniforge3/lib/python3.9/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_mod.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3a1257d1-95c0-4e21-9339-f0eb1b444d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693083, 2)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "72a0d4ae-d189-4f89-adb9-fc5228f510be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_mod.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "79c20bf7-8144-40b0-8813-ddd78854489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_mod.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63984a4-3efa-4176-a2e5-daa025288309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9b52d66e-7799-494c-b1e0-d3b4596730e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f9cd6-36b1-43b0-b53f-44755a07592c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "74c6af09-4495-4a6c-b708-e0b46e13184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "669835db-92dd-44da-b56e-27c08bc95f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created a NLP processing function that includes all the steps of corpus cleaning and creation and\n",
    "# vectorization\n",
    "\n",
    "def NLP_process(data):\n",
    "    BoW=[]\n",
    "    for word in data:\n",
    "        BoW.append(word)\n",
    "    word_bank= ' '.join(BoW)\n",
    "    word_bank= word_bank.lower()\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    tokenized_tweets= tokenizer.tokenize(word_bank)\n",
    "\n",
    "    sw_list = stopwords.words('english')\n",
    "    sw_list += list(string.punctuation)\n",
    "    sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘', '©', '#', '@', \n",
    "            'said', 'one', 'com', '-', '–', '—', '.']\n",
    "    sw_list += ['www', 'the', 'to', 'and', 'a', 's', 't','is', 'you', 'of', 'i', \n",
    "            'in', 'this', 'are', 'it', 'for', 'https', 'com', \n",
    "             'p',]\n",
    "    sw_set = set(sw_list)\n",
    "    filtered_tweets=[]\n",
    "    for word in tokenized_tweets:\n",
    "        if word not in sw_set:\n",
    "            filtered_tweets.append(word)\n",
    "#     \n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    X_lemmatized_tweets=[]\n",
    "    for w in filtered_tweets:\n",
    "        X_lemmatized_tweets.append(lemmatizer.lemmatize(w))\n",
    "    X_lemmatized_tweets\n",
    "    \n",
    "    tfidf = TfidfVectorizer(stop_words=sw_list, ngram_range=(1,1), lowercase=True)\n",
    "    tfidf_data_test_lem = tfidf.fit_transform(X_lemmatized_tweets)\n",
    "    return tfidf_data_test_lem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "0624c235-068c-4e04-83d2-b57e52ede9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b=NLP_process(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f6453068-ceb0-43e0-80d6-382455676779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def NLP_process_t(data):\n",
    "    BoW=[]\n",
    "    for word in data:\n",
    "        BoW.append(word)\n",
    "    word_bank= ' '.join(BoW)\n",
    "    word_bank= word_bank.lower()\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    tokenized_tweets= tokenizer.tokenize(word_bank)\n",
    "\n",
    "    sw_list = stopwords.words('english')\n",
    "    sw_list += list(string.punctuation)\n",
    "    sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘', '©', '#', '@', \n",
    "            'said', 'one', 'com', '-', '–', '—', '.']\n",
    "    sw_list += ['www', 'the', 'to', 'and', 'a', 's', 't','is', 'you', 'of', 'i', \n",
    "            'in', 'this', 'are', 'it', 'for', 'https', 'com', \n",
    "             'p',]\n",
    "    sw_set = set(sw_list)\n",
    "    filtered_tweets=[]\n",
    "    for word in tokenized_tweets:\n",
    "        if word not in sw_set:\n",
    "            filtered_tweets.append(word)\n",
    "#     \n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    X_lemmatized_tweets=[]\n",
    "    for w in filtered_tweets:\n",
    "        X_lemmatized_tweets.append(lemmatizer.lemmatize(w))\n",
    "    X_lemmatized_tweets\n",
    "    \n",
    "    tfidf = TfidfVectorizer(stop_words=sw_list, ngram_range=(1,1), lowercase=True)\n",
    "    tfidf_data_test_lem = tfidf.transform(X_lemmatized_tweets)\n",
    "    return tfidf_data_test_lem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "eadfeaff-fbe9-4f94-ab7b-982eb64271a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/48/3rfqt3q17zj4zsvn_9rh50br0000gn/T/ipykernel_10716/383348047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNLP_process_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/48/3rfqt3q17zj4zsvn_9rh50br0000gn/T/ipykernel_10716/4211779253.py\u001b[0m in \u001b[0;36mNLP_process_t\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtfidf_data_test_lem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lemmatized_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtfidf_data_test_lem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         \"\"\"\n\u001b[0;32m-> 2099\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "X_t=NLP_process_t(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "75b46372-e55c-423d-a3e0-28b4df7b0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tf_idf vectorizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,1), lowercase=True)\n",
    "tfidf_data_train_lem = tfidf.fit_transform(X_train)\n",
    "tfidf_data_test_lem = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c96118cb-6841-4caf-a913-f6645ec621ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyng/miniforge3/lib/python3.9/site-packages/sklearn/naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "classifier = MultinomialNB(alpha=0)  \n",
    "classifier.fit(tfidf_data_train_lem, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e0108cfd-933b-46ec-88ae-2eddd60e47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=classifier.predict(tfidf_data_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e6b58755-d88e-49cc-a7ad-fd3d55315a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e4b4384c-df2b-40a5-b1b1-c1f0ed7f5c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9805002272448545\n",
      "0.9803130732680493\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_preds))\n",
    "print(metrics.f1_score(y_test, y_preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc71e8-0aec-4c36-ac0d-733dd0a1f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709aebd-5db3-4787-a34d-c6a28b32007d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f39240-aad1-4e2b-b234-68a536ec4a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7047c0f-9f9a-412f-ab46-8bf3562e50b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6f0f3f4-f1a8-4c6d-ab65-82dc564c55b9",
   "metadata": {},
   "source": [
    "### We will find the sentiment score fro each review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e52558b-b6ef-41dd-8930-204a62a6c6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63001, 9)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff768c0a-4baf-47ae-9e8e-3a5c74ab8015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0    We got this GPS for my husband who is an ...\n",
       "5          5    I am using this with a Nook HD+. It works...\n",
       "10         10    This item is just as was described in th...\n",
       "18         18     This is a great buy, compared to a $60 ...\n",
       "237        237    The Nook Tablet, in both the 16gb versi...\n",
       "                                 ...                        \n",
       "1689106    1689106    The Sabrent CR-CCU3 Card reader is ...\n",
       "1689125    1689125    Great hub for carrying around if yo...\n",
       "1689142    1689142    This is an interesting device in th...\n",
       "1689162    1689162    ...all part of the package that com...\n",
       "1689183    1689183    Burned these in before listening to...\n",
       "Name: reviewText, Length: 63001, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ebce3fa-5c94-4eee-8344-c5b567813153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3b64a2b-8fbb-4d2a-8ea6-ebe3b4372cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "797096e5-602b-4b05-9d4a-ea58645a7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 1689188/1689188 [31:06<00:00, 904.93it/s]\n"
     ]
    }
   ],
   "source": [
    "sent=[sid.polarity_scores(x) for x in tqdm(df.reviewText)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3e25c-83ca-43b2-8132-492017b14b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da8f854d-d965-484a-8e66-756f66d1c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_score']=[sent[x].get('compound') for x in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "006031a7-ec11-41a5-afd5-cc862244635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapped Vader scores to integer counts for easier manipulation \n",
    "col         = 'vader_score'\n",
    "conditions  = [ df[col] >= .15, (df[col] < .1) & (df[col]> -.1), df[col] <= -.1 ]\n",
    "choices     = [ 1, 0, -1 ]\n",
    "df[\"vader_score\"] = np.select(conditions, choices, default=np.nan)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4f63d0c-6d73-43b0-850f-c86b1d4511e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final mapping process\n",
    "df['vader_score']= df['vader_score'].map({-1:'negative', 0: 'neutral', 1:'positive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "71280e02-4e71-42a7-8ee5-bf83a62955eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1399723\n",
       "negative     194525\n",
       "neutral       80603\n",
       "Name: vader_score, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.vader_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08493153-7c78-4a7a-831f-4e4a7b064c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72635dbc-ebf0-47e7-9024-e88d18895d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3dc55eb-9052-426e-aa41-49530bbc7c1f",
   "metadata": {},
   "source": [
    "### We will use Spacy Embeddings for the df.reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1db4cf2-aceb-42cf-877b-5e7dfaebd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing spacy \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0d6fa1e-05fa-4792-9daf-bcf7b25b6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "spacy_tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5447c12-4b73-488e-aa72-c6d8e62c33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to take reviewText column an return word embedding\n",
    "def prep(x):\n",
    "    z=spacy_tokenizer(x) \n",
    "    z=nlp(z).vector.reshape(300,)\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fab78887-3f99-41bd-9997-6531a35890ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tdqm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/48/3rfqt3q17zj4zsvn_9rh50br0000gn/T/ipykernel_10716/900492831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtdqm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviewText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tdqm' is not defined"
     ]
    }
   ],
   "source": [
    "words=tdqm([prep(x) for x in df.reviewText])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a78b5a-c8b4-47e9-9475-d3dda3234346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b17aa97f-f070-40ec-9b53-1850178b06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# set the correct path to the file on your machine\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('~/Downloads/crawl-300d-2M.vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a2ffc31d-1def-4296-af33-ec92244964a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(word2vec_model, words):\n",
    "    # remove out-of-vocabulary words\n",
    "    words = [word for word in words if word in word2vec_model.key_to_index]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(word2vec_model[words], axis=0)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2bd23045-277d-4af6-ba63-a5e97dcc15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [get_mean_vector(model, df.reviewText[i]) for i in tqdm(range(len(df.reviewText)))]\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72176917-fd3f-413a-9f2a-60fc1f3ed9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "da78da12-2345-45de-b7c6-b48b5e9c8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc284740-6eab-45ce-b504-de047264d51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f20f10-1ee9-44be-9c2b-0f75151eb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagger(x):\n",
    "    y_pred=model.predict(x)\n",
    "    new_df=df[df.tag==str(y_pred)]\n",
    "    new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11daf5fb-7b4d-4351-9ae2-d9e4fe404682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_calc(x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f479c15-eac0-4272-a221-997e882517b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Models.Sequential()\n",
    "model1 = Sequential()\n",
    "\n",
    "model2 = Model(inputs=[model.input, model1.input], outputs=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
